{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "/anaconda/envs/py35/lib/python3.5/site-packages/xapian/_xapian.cpython-35m-x86_64-linux-gnu.so: undefined symbol: _ZN6Xapian12TermIterator7skip_toERKSs",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-f07da2f77f34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mxapian\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda/envs/py35/lib/python3.5/site-packages/xapian/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_xapian\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_swig_setattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: /anaconda/envs/py35/lib/python3.5/site-packages/xapian/_xapian.cpython-35m-x86_64-linux-gnu.so: undefined symbol: _ZN6Xapian12TermIterator7skip_toERKSs"
     ]
    }
   ],
   "source": [
    "import xapian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbpath = \"full_index\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "zf = ZipFile(\"../wiki-pages-text.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = [item.filename for item in zf.filelist]\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_shard(zf, path):\n",
    "    items = []\n",
    "    fp = zf.open(path, mode='r')\n",
    "    tfp = io.TextIOWrapper(fp)\n",
    "    for line in tfp.readlines():\n",
    "        match = re.match(\"(\\w+)\\s(\\d+)\\s(.*)\\n\", line)\n",
    "        if match:\n",
    "            items.append(match.groups())\n",
    "    fp.close()\n",
    "    tfp.close()\n",
    "    return items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_shard_as_df(zf, path):\n",
    "    items = read_shard(zf, path)\n",
    "    raw_df = pd.DataFrame(data=items, columns=['doc_id', 'sentence', 'text'])\n",
    "    func = lambda x: \" \".join(x)\n",
    "    return raw_df.groupby('doc_id')['text'].agg(func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wiki-pages-text/wiki-009.txt\n",
      "wiki-pages-text/wiki-021.txt\n",
      "wiki-pages-text/wiki-035.txt\n",
      "wiki-pages-text/wiki-034.txt\n",
      "wiki-pages-text/wiki-020.txt\n",
      "wiki-pages-text/wiki-008.txt\n",
      "wiki-pages-text/wiki-036.txt\n",
      "wiki-pages-text/wiki-022.txt\n",
      "wiki-pages-text/wiki-023.txt\n",
      "wiki-pages-text/wiki-037.txt\n",
      "wiki-pages-text/wiki-033.txt\n",
      "wiki-pages-text/wiki-027.txt\n",
      "wiki-pages-text/wiki-026.txt\n",
      "wiki-pages-text/wiki-032.txt\n",
      "wiki-pages-text/wiki-024.txt\n",
      "wiki-pages-text/wiki-030.txt\n",
      "wiki-pages-text/wiki-018.txt\n",
      "wiki-pages-text/wiki-019.txt\n",
      "wiki-pages-text/wiki-031.txt\n",
      "wiki-pages-text/wiki-025.txt\n",
      "wiki-pages-text/wiki-042.txt\n",
      "wiki-pages-text/wiki-056.txt\n",
      "wiki-pages-text/wiki-081.txt\n",
      "wiki-pages-text/wiki-095.txt\n",
      "wiki-pages-text/wiki-094.txt\n",
      "wiki-pages-text/wiki-080.txt\n",
      "wiki-pages-text/wiki-057.txt\n",
      "wiki-pages-text/wiki-043.txt\n",
      "wiki-pages-text/wiki-069.txt\n",
      "wiki-pages-text/wiki-055.txt\n",
      "wiki-pages-text/wiki-041.txt\n",
      "wiki-pages-text/wiki-096.txt\n",
      "wiki-pages-text/wiki-082.txt\n",
      "wiki-pages-text/wiki-109.txt\n",
      "wiki-pages-text/wiki-108.txt\n",
      "wiki-pages-text/wiki-083.txt\n",
      "wiki-pages-text/wiki-097.txt\n",
      "wiki-pages-text/wiki-040.txt\n",
      "wiki-pages-text/wiki-054.txt\n",
      "wiki-pages-text/wiki-068.txt\n",
      "wiki-pages-text/wiki-050.txt\n",
      "wiki-pages-text/wiki-044.txt\n",
      "wiki-pages-text/wiki-078.txt\n",
      "wiki-pages-text/wiki-093.txt\n",
      "wiki-pages-text/wiki-087.txt\n",
      "wiki-pages-text/wiki-086.txt\n",
      "wiki-pages-text/wiki-092.txt\n",
      "wiki-pages-text/wiki-079.txt\n",
      "wiki-pages-text/wiki-045.txt\n",
      "wiki-pages-text/wiki-051.txt\n",
      "wiki-pages-text/wiki-047.txt\n",
      "wiki-pages-text/wiki-053.txt\n",
      "wiki-pages-text/wiki-084.txt\n",
      "wiki-pages-text/wiki-090.txt\n",
      "wiki-pages-text/wiki-091.txt\n",
      "wiki-pages-text/wiki-085.txt\n",
      "wiki-pages-text/wiki-052.txt\n",
      "wiki-pages-text/wiki-046.txt\n",
      "wiki-pages-text/wiki-063.txt\n",
      "wiki-pages-text/wiki-077.txt\n",
      "wiki-pages-text/wiki-088.txt\n",
      "wiki-pages-text/wiki-103.txt\n",
      "wiki-pages-text/wiki-102.txt\n",
      "wiki-pages-text/wiki-089.txt\n",
      "wiki-pages-text/wiki-076.txt\n",
      "wiki-pages-text/wiki-062.txt\n",
      "wiki-pages-text/wiki-048.txt\n",
      "wiki-pages-text/wiki-074.txt\n",
      "wiki-pages-text/wiki-060.txt\n",
      "wiki-pages-text/wiki-100.txt\n",
      "wiki-pages-text/wiki-101.txt\n",
      "wiki-pages-text/wiki-061.txt\n",
      "wiki-pages-text/wiki-075.txt\n",
      "wiki-pages-text/wiki-049.txt\n",
      "wiki-pages-text/wiki-071.txt\n",
      "wiki-pages-text/wiki-065.txt\n",
      "wiki-pages-text/wiki-059.txt\n",
      "wiki-pages-text/wiki-105.txt\n",
      "wiki-pages-text/wiki-104.txt\n",
      "wiki-pages-text/wiki-058.txt\n",
      "wiki-pages-text/wiki-064.txt\n",
      "wiki-pages-text/wiki-070.txt\n",
      "wiki-pages-text/wiki-066.txt\n",
      "wiki-pages-text/wiki-072.txt\n",
      "wiki-pages-text/wiki-099.txt\n",
      "wiki-pages-text/wiki-106.txt\n",
      "wiki-pages-text/wiki-107.txt\n",
      "wiki-pages-text/wiki-098.txt\n",
      "wiki-pages-text/wiki-073.txt\n",
      "wiki-pages-text/wiki-067.txt\n",
      "wiki-pages-text/wiki-028.txt\n",
      "wiki-pages-text/wiki-014.txt\n",
      "wiki-pages-text/wiki-015.txt\n",
      "wiki-pages-text/wiki-001.txt\n",
      "wiki-pages-text/wiki-029.txt\n",
      "wiki-pages-text/wiki-017.txt\n",
      "wiki-pages-text/wiki-003.txt\n",
      "wiki-pages-text/wiki-002.txt\n",
      "wiki-pages-text/wiki-016.txt\n",
      "wiki-pages-text/wiki-012.txt\n",
      "wiki-pages-text/wiki-006.txt\n",
      "wiki-pages-text/wiki-007.txt\n",
      "wiki-pages-text/wiki-013.txt\n",
      "wiki-pages-text/wiki-005.txt\n",
      "wiki-pages-text/wiki-011.txt\n",
      "wiki-pages-text/wiki-039.txt\n",
      "wiki-pages-text/wiki-038.txt\n",
      "wiki-pages-text/wiki-010.txt\n",
      "wiki-pages-text/wiki-004.txt\n",
      "CPU times: user 41min 43s, sys: 40min 33s, total: 1h 22min 16s\n",
      "Wall time: 1h 42min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Create or open the database we're going to be writing to.\n",
    "db = xapian.WritableDatabase(dbpath, xapian.DB_CREATE_OR_OPEN)\n",
    "\n",
    "# Set up a TermGenerator that we'll use in indexing.\n",
    "termgenerator = xapian.TermGenerator()\n",
    "termgenerator.set_stemmer(xapian.Stem(\"en\"))\n",
    "\n",
    "for path in sorted(files[1:]):\n",
    "    print(path)\n",
    "    documents_df = read_shard_as_df(zf, path)\n",
    "    for doc_id, text in documents_df.items():\n",
    "        # We make a document and tell the term generator to use this.\n",
    "        doc = xapian.Document()\n",
    "        termgenerator.set_document(doc)\n",
    "\n",
    "        # Index each field with a suitable prefix.\n",
    "        termgenerator.index_text(doc_id, 1, 'S')\n",
    "        #termgenerator.index_text(description, 1, 'XD')\n",
    "\n",
    "        # Index fields without prefixes for general search.\n",
    "        termgenerator.index_text(text)\n",
    "        termgenerator.increase_termpos()\n",
    "        #termgenerator.index_text(description)\n",
    "\n",
    "        # We use the identifier to ensure each object ends up in the\n",
    "        # database only once no matter how many times we run the\n",
    "        # indexer.\n",
    "        idterm = u\"Q\" + doc_id\n",
    "        doc.add_boolean_term(idterm)\n",
    "        db.replace_document(idterm, doc)\n",
    "db.commit()\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UUID = b940719a-3fb5-4d57-8b01-3186790b1ade\r\n",
      "number of documents = 3833466\r\n",
      "average document length = 170.939\r\n",
      "document length lower bound = 1\r\n",
      "document length upper bound = 31154\r\n",
      "highest document id ever used = 3833466\r\n",
      "has positional information = true\r\n",
      "revision = 392\r\n",
      "currently open for writing = false\r\n"
     ]
    }
   ],
   "source": [
    "!xapian-delve $dbpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for record #1833129:\r\n",
      "\r\n",
      "Term List for record #1833129: 17 2004 2007 3 QKim_Hyde Skim_hyde ZSkim_hyd Za Zand Zappear Zaustralian Zaway Zby Zcharact Zchris Zdepart Zfebruari Zfiction Zfirst Zfrom Zhe Zhemsworth Zhis Zhome Zhyde Zjonathan Zjuli Zkim Zkimber Zmade Zon Zopera Zplay Zscreen Zsoap Zthe Zwas a and appearance australian away by character chris departed february fictional first from he hemsworth his home hyde jonathan july kim kimberly made on opera played screen soap the was\r\n"
     ]
    }
   ],
   "source": [
    "!xapian-delve -r 1833129 -d $dbpath"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
