{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import json\n",
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import xapian\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DBPATH = \"bigrams_index\"\n",
    "PARSED_CORPUS = 'data/parsed_corpus'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(DBPATH):\n",
    "    os.mkdir(DBPATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "zf = ZipFile(\"../wiki-pages-text.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(110, 'wiki-pages-text/wiki-009.txt')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = [item.filename for item in zf.filelist]\n",
    "len(files), files[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_shard(zf, path):\n",
    "    items = []\n",
    "    fp = zf.open(path, mode='r')\n",
    "    tfp = io.TextIOWrapper(fp)\n",
    "    nlines = 0\n",
    "    for line in tfp.readlines():\n",
    "        nlines += 1\n",
    "        match = re.match(\"(\\S+)\\s(\\d+)\\s(.*)\\n\", line)\n",
    "        if match:\n",
    "            items.append(match.groups())\n",
    "        else:\n",
    "            #print(line)\n",
    "            pass\n",
    "    fp.close()\n",
    "    tfp.close()\n",
    "    return items#, nlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = sorted(files[1:])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wiki-pages-text/wiki-001.txt\n",
      "wiki-pages-text/wiki-002.txt\n",
      "wiki-pages-text/wiki-003.txt\n",
      "wiki-pages-text/wiki-004.txt\n",
      "wiki-pages-text/wiki-005.txt\n",
      "wiki-pages-text/wiki-006.txt\n",
      "wiki-pages-text/wiki-007.txt\n",
      "wiki-pages-text/wiki-008.txt\n",
      "wiki-pages-text/wiki-009.txt\n",
      "wiki-pages-text/wiki-010.txt\n",
      "wiki-pages-text/wiki-011.txt\n",
      "wiki-pages-text/wiki-012.txt\n",
      "wiki-pages-text/wiki-013.txt\n",
      "wiki-pages-text/wiki-014.txt\n",
      "wiki-pages-text/wiki-015.txt\n",
      "wiki-pages-text/wiki-016.txt\n",
      "wiki-pages-text/wiki-017.txt\n",
      "wiki-pages-text/wiki-018.txt\n",
      "wiki-pages-text/wiki-019.txt\n",
      "wiki-pages-text/wiki-020.txt\n",
      "wiki-pages-text/wiki-021.txt\n",
      "wiki-pages-text/wiki-022.txt\n",
      "wiki-pages-text/wiki-023.txt\n",
      "wiki-pages-text/wiki-024.txt\n",
      "wiki-pages-text/wiki-025.txt\n",
      "wiki-pages-text/wiki-026.txt\n",
      "wiki-pages-text/wiki-027.txt\n",
      "wiki-pages-text/wiki-028.txt\n",
      "wiki-pages-text/wiki-029.txt\n",
      "wiki-pages-text/wiki-030.txt\n",
      "wiki-pages-text/wiki-031.txt\n",
      "wiki-pages-text/wiki-032.txt\n",
      "wiki-pages-text/wiki-033.txt\n",
      "wiki-pages-text/wiki-034.txt\n",
      "wiki-pages-text/wiki-035.txt\n",
      "wiki-pages-text/wiki-036.txt\n",
      "wiki-pages-text/wiki-037.txt\n",
      "wiki-pages-text/wiki-038.txt\n",
      "wiki-pages-text/wiki-039.txt\n",
      "wiki-pages-text/wiki-040.txt\n",
      "wiki-pages-text/wiki-041.txt\n",
      "wiki-pages-text/wiki-042.txt\n",
      "wiki-pages-text/wiki-043.txt\n",
      "wiki-pages-text/wiki-044.txt\n",
      "wiki-pages-text/wiki-045.txt\n",
      "wiki-pages-text/wiki-046.txt\n",
      "wiki-pages-text/wiki-047.txt\n",
      "wiki-pages-text/wiki-048.txt\n",
      "wiki-pages-text/wiki-049.txt\n",
      "wiki-pages-text/wiki-050.txt\n",
      "wiki-pages-text/wiki-051.txt\n",
      "wiki-pages-text/wiki-052.txt\n",
      "wiki-pages-text/wiki-053.txt\n",
      "wiki-pages-text/wiki-054.txt\n",
      "wiki-pages-text/wiki-055.txt\n",
      "wiki-pages-text/wiki-056.txt\n",
      "wiki-pages-text/wiki-057.txt\n",
      "wiki-pages-text/wiki-058.txt\n",
      "wiki-pages-text/wiki-059.txt\n",
      "wiki-pages-text/wiki-060.txt\n",
      "List_of_cosmopterigid_genera The moth family Cosmopterigidae contains the following genera : Acanthophlebia Acleracra Adeana Aeaea Aeronectris Afeda Aganoptila Agonismus Alloclita Allotalanta Amaurogramma Amblytenes Ambonostola Anataractis ` AnatrachyntisAnonciaAnorcotaAntequeraAphanosaraAphthonetusApothetodesArchisophaAscaleniaAshibusaAsymphorodesAxiarchaBalionebrisBathraulaBathybaliaBifascioidesBubalocerasCalanesiaCallixestisCalycobathraCholotisChrysopeleiaClemmatistaColonophoraCosmiosophistaCosmopterixCrobylophanesCyphothyrisCystioecetesDhahraniaDiatonicaDiophilaDiplosaraDiversivalvaDorodocaDromiaulisDynatophysisDysphoriaEcballogoniaEchinoscelisEndograptisEraleaErechthiodesEritarbesEteobaleaEuamnerisEuclemensiaEuhyposmocomaEumenodoraEuperissusFalcatariellaGisiliaGlaphyristisGriphocosmaHaplochroisHaplophylaxHarpograptisHedroxenaHelicacmaHerlindaHeterotactisHodgesiellaHomosacesHyalochnaHyperdasysellaHyposmocomaIdiostylaIressaIschnangelaIschnobathraIsidiellaIsostreptisIthomeLabdiaLalliaLeptozestisLimnaeciaMacrobathraMelanocinclisMelanozestisMeleonomaMelneaMeneptilaMetagrypaMicrozestisMinivalvaMothonodesNeachandellaNeelysiaNeomarianiaNepotulaObithomeOpszygaOrthromictaOtonomaPancaliaParastagmatophoraParathystasPassalotisPauroptilaPebopsPechyptilaPerimedePeriplocaPersicoptilaPharmacoptisPhepsalostomaPhosphaticolaPhthoraulaPristenProterocosmaProtogrypaProtorhizaPseudascaleniaPtilocharesPycnagorastisPyretaulaxPyrodercesRamphisRessiaRhadinastisRhinomactrumSathrobrotaScaeosophaScaeothyrisSchendylotisSematoptisSemnoprepiaSemolinaSindicolaSiskiwitiaSorhageniaSorhageniellaSpirotermaStagmatophoraStilbosisStreptothyrisStromatiticaStrophalingiasSynplocaSyntomactisSyntomaulaTanygonaTeladomaThalerostomaThectophilaTolliellaTrachydoraTriclonellaTrissodorisUlochoraUrangelaVulcaniellaWalshiaZanclarches '' Term too long (> 245): anataractis_anatrachyntisanonciaanorcotaantequeraaphanosaraaphthonetusapothetodesarchisophaascaleniaashibusaasymphorodesaxiarchabalionebrisbathraulabathybaliabifascioidesbubalocerascalanesiacallixestiscalycobathracholotischrysopeleiaclemmatistacolonophoracosmiosophistacosmopterixcrobylophanescyphothyriscystioecetesdhahraniadiatonicadiophiladiplosaradiversivalvadorodocadromiaulisdynatophysisdysphoriaecballogoniaechinoscelisendograptiseraleaerechthiodeseritarbeseteobaleaeuamneriseuclemensiaeuhyposmocomaeumenodoraeuperissusfalcatariellagisiliaglaphyristisgriphocosmahaplochroishaplophylaxharpograptishedroxenahelicacmaherlindaheterotactishodgesiellahomosaceshyalochnahyperdasysellahyposmocomaidiostylairessaischnangelaischnobathraisidiellaisostreptisithomelabdialallialeptozestislimnaeciamacrobathramelanocinclismelanozestismeleonomamelneameneptilametagrypamicrozestisminivalvamothonodesneachandellaneelysianeomarianianepotulaobithomeopszygaorthromictaotonomapancaliaparastagmatophoraparathystaspassalotispauroptilapebopspechyptilaperimedeperiplocapersicoptilapharmacoptisphepsalostomaphosphaticolaphthoraulapristenproterocosmaprotogrypaprotorhizapseudascaleniaptilocharespycnagorastispyretaulaxpyrodercesramphisressiarhadinastisrhinomactrumsathrobrotascaeosophascaeothyrisschendylotissematoptissemnoprepiasemolinasindicolasiskiwitiasorhageniasorhageniellaspirotermastagmatophorastilbosisstreptothyrisstromatiticastrophalingiassynplocasyntomactissyntomaulatanygonateladomathalerostomathectophilatolliellatrachydoratriclonellatrissodorisulochoraurangelavulcaniellawalshiazanclarches\n",
      "wiki-pages-text/wiki-061.txt\n",
      "Lopadotemachoselachogaleokranioleipsanodrimhypotrimmatosilphioparaomelitokatakechymenokichlepikossyphophattoperisteralektryonoptekephalliokigklopeleiolagoiosiraiobaphetraganopterygon '' ` Lopadotemachoselachogaleokranioleipsanodrimhypotrimmatosilphioparaomelitokatakechymenokichlepikossyphophattoperisteralektryonoptekephalliokigklopeleiolagoiosiraiobaphetraganopterygon '' ' is a fictional -LSB- -LSB- Dish -LRB- food -RRB- | dish -RSB- -RSB- mentioned in -LSB- -LSB- Aristophanes -RSB- -RSB- ' comedy '' -LSB- -LSB- Assemblywomen -RSB- -RSB- . '' It is a -LSB- -LSB- transliteration -RSB- -RSB- of the Ancient Greek word -LSB- -LSB- Wiktionary : Unsupported titles/Ancient Greek dish | λοπαδοτεμαχοσελαχογαλεοκρανιολειψανοδριμυποτριμματοσιλφιοκαραβομελιτοκατακεχυμενοκιχλεπικοσσυφοφαττοπεριστεραλεκτρυονοπτοκεφαλλιοκιγκλοπελειολαγῳοσιραιοβαφητραγανοπτερύγων -RSB- -RSB- . -LSB- -LSB- A Greek-English Lexicon | Liddell & Scott -RSB- -RSB- -LRB- LSJ -RRB- translate this as `` name of a dish compounded of all kinds of dainties , fish , flesh , fowl , and sauces . '' The Greek word has 172 letters , 78 syllables , and 182 Latin characters . It is the longest word ever to appear in literature according to -LSB- -LSB- Guinness World Records -RSB- -RSB- -LRB- 1990 -RRB- . Term too long (> 245): |_λοπαδοτεμαχοσελαχογαλεοκρανιολειψανοδριμυποτριμματοσιλφιοκαραβομελιτοκατακεχυμενοκιχλεπικοσσυφοφαττοπεριστεραλεκτρυονοπτοκεφαλλιοκιγκλοπελειολαγῳοσιραιοβαφητραγανοπτερύγων\n",
      "wiki-pages-text/wiki-062.txt\n",
      "wiki-pages-text/wiki-063.txt\n",
      "wiki-pages-text/wiki-064.txt\n",
      "wiki-pages-text/wiki-065.txt\n",
      "wiki-pages-text/wiki-066.txt\n",
      "wiki-pages-text/wiki-067.txt\n",
      "wiki-pages-text/wiki-068.txt\n",
      "wiki-pages-text/wiki-069.txt\n",
      "wiki-pages-text/wiki-070.txt\n",
      "wiki-pages-text/wiki-071.txt\n",
      "wiki-pages-text/wiki-072.txt\n",
      "wiki-pages-text/wiki-073.txt\n",
      "wiki-pages-text/wiki-074.txt\n",
      "wiki-pages-text/wiki-075.txt\n",
      "wiki-pages-text/wiki-076.txt\n",
      "wiki-pages-text/wiki-077.txt\n",
      "wiki-pages-text/wiki-078.txt\n",
      "People's_Democratic_Reform_Committee The People 's Democratic Reform Committee -LRB- PDRC -RRB- or People 's Committee for Absolute Democracy with the King as Head of State -LRB- PCAD -RRB- -LRB- คณะกรรมการประชาชนเพื่อการเปลี่ยนแปลงประเทศไทยให้เป็นประชาธิปไตยที่สมบูรณ์ อันมีพระมหากษัตริย์ทรงเป็นประมุข , กปปส. , literally `` people 's committee for changing Thailand into a complete democracy with the king as head of state '' -RRB- was an umbrella political pressure group in Thailand , aimed at removing the influence of former premier Thaksin Shinawatra from Thai politics and achieve political reforms by an unelected ` People 's Council ' . The group played a leading role in the 2013 -- 14 Thai political crisis , organising large-scale protests within Bangkok . The group was formed on 29 November 2013 by protest leader and former Democrat Party MP Suthep Thaugsuban , who appointed himself as secretary-general . The movement was supported by various organisations including the Democrat Party , the People 's Alliance for Democracy -LRB- a coalition of opposition to Thaksin -RRB- , student activist groups , state worker 's unions and pro-military groups . The PDRC 's support stemmed mostly from affluent Bangkokians and Southerners . Whistle-blowing was a central symbol of the protests . By accusing the government of lacking any legitimacy , Suthep Thaugsuban announced the intention of the People 's Democratic Reform Committee to take back sovereign power from the government and proceed with national reform through a non-elected royalist council , in order to `` eradicate '' the `` Thaksin regime '' . Suthep outlined plans for the council to `` act as a legislative body , amend laws and regulations , as well as carry out a reform plan in the country '' . He also explained the council would have 400 members , 300 of whom would be representatives from various professions . The remaining 100 would be selected by the PDRC from scholars and well-respected senior citizens . The ultimate goal of the PDRC was to have the prime minister Yingluck Shinawatra resign as the head of the caretaker government in order to allow a power vacuum then invoke article 3 `` The sovereign power belongs to the Thai people . The King as Head of State shall exercise such power through the National Assembly , the Council of Ministers and the Courts in accordance with the provisions of this Constitution . '' and article 7 `` Whenever no provision under this Constitution is applicable to any case , it shall be decided in accordance with the constitutional convention in the democratic regime of government with the King as Head of State . '' of the 2007 Constitution . This would have allowed the head of the senate to appoint a new premier . Yingluck and nine other senior ministers were removed from office by Constitutional Court on 7 May 2014 . The military then seized power in a coup d'état on 22 May , a move which was applauded by many PDRC protesters . The PDRC was disbanded shortly after the coup . Term too long (> 245): คณะกรรมการประชาชนเพื่อการเปลี่ยนแปลงประเทศไทยให้เป็นประชาธิปไตยที่สมบูรณ์_อันมีพระมหากษัตริย์ทรงเป็นประมุข\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wiki-pages-text/wiki-079.txt\n",
      "wiki-pages-text/wiki-080.txt\n",
      "wiki-pages-text/wiki-081.txt\n",
      "wiki-pages-text/wiki-082.txt\n",
      "wiki-pages-text/wiki-083.txt\n",
      "wiki-pages-text/wiki-084.txt\n",
      "wiki-pages-text/wiki-085.txt\n",
      "wiki-pages-text/wiki-086.txt\n",
      "wiki-pages-text/wiki-087.txt\n",
      "wiki-pages-text/wiki-088.txt\n",
      "wiki-pages-text/wiki-089.txt\n",
      "wiki-pages-text/wiki-090.txt\n",
      "wiki-pages-text/wiki-091.txt\n",
      "wiki-pages-text/wiki-092.txt\n",
      "wiki-pages-text/wiki-093.txt\n",
      "wiki-pages-text/wiki-094.txt\n",
      "wiki-pages-text/wiki-095.txt\n",
      "wiki-pages-text/wiki-096.txt\n",
      "wiki-pages-text/wiki-097.txt\n",
      "wiki-pages-text/wiki-098.txt\n",
      "wiki-pages-text/wiki-099.txt\n",
      "wiki-pages-text/wiki-100.txt\n",
      "wiki-pages-text/wiki-101.txt\n",
      "wiki-pages-text/wiki-102.txt\n",
      "wiki-pages-text/wiki-103.txt\n",
      "wiki-pages-text/wiki-104.txt\n",
      "wiki-pages-text/wiki-105.txt\n",
      "wiki-pages-text/wiki-106.txt\n",
      "wiki-pages-text/wiki-107.txt\n",
      "wiki-pages-text/wiki-108.txt\n",
      "wiki-pages-text/wiki-109.txt\n",
      "CPU times: user 2h 15min 53s, sys: 5h 43min 25s, total: 7h 59min 19s\n",
      "Wall time: 10h 7min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Create or open the database we're going to be writing to.\n",
    "db = xapian.WritableDatabase(DBPATH, xapian.DB_CREATE_OR_OPEN)\n",
    "\n",
    "# Set up a TermGenerator that we'll use in indexing.\n",
    "termgenerator = xapian.TermGenerator()\n",
    "termgenerator.set_stemmer(xapian.Stem(\"en\"))\n",
    "\n",
    "for path in sorted(files[1:]):\n",
    "    shard = \"\"\n",
    "    m = re.match(\".*wiki-(\\d+).*\", path)\n",
    "    if m: shard = m[1]\n",
    "    print(path)\n",
    "    \n",
    "    items = read_shard(zf, path)\n",
    "    raw_df = pd.DataFrame(data=items, columns=['page_id', 'sentence', 'text'])\n",
    "\n",
    "    # text\n",
    "    func = lambda x: \" \".join(x)\n",
    "    docs_df = raw_df.groupby('page_id')['text'].agg(func)\n",
    "\n",
    "    # keywords\n",
    "    keywords_df = pd.read_json('{}/{}.json'.format(PARSED_CORPUS, shard), orient='split')#.set_index(index_cols)\n",
    "    func = lambda ngrams: [\"_\".join(ngram).lower() for ngram in ngrams]\n",
    "    keywords_df['ngrams'] = keywords_df.keywords.apply(lambda x: func(nltk.bigrams(x))) #\\\n",
    "    #                        + keywords_df.keywords.apply(lambda x: func(nltk.trigrams(x)))\n",
    "\n",
    "    # bi/tri-grams\n",
    "    def func(items): return set(items)\n",
    "    ngrams_series = keywords_df.groupby('page_id')['ngrams'].agg(sum).apply(func)\n",
    "\n",
    "    # sentences\n",
    "    raw_df['sentence'] = raw_df['sentence'].astype(int)\n",
    "    raw_df['text'] = raw_df.apply(lambda v: {'sent_id': v['sentence'], 'text': v['text']}, axis=1)\n",
    "    sentences_series = raw_df.groupby('page_id')['text'].agg(list)\n",
    "    \n",
    "    for page_id, text in docs_df.items():\n",
    "        try:\n",
    "            # We make a document and tell the term generator to use this.\n",
    "            doc = xapian.Document()\n",
    "            termgenerator.set_document(doc)\n",
    "\n",
    "            # Index fields without prefixes for general search.\n",
    "            termgenerator.index_text(text)\n",
    "            termgenerator.increase_termpos()\n",
    "\n",
    "            # We use the identifier to ensure each object ends up in the\n",
    "            # database only once no matter how many times we run the\n",
    "            # indexer.\n",
    "            idterm = u\"Q\" + page_id\n",
    "            doc.add_boolean_term(idterm)\n",
    "\n",
    "            # Indexing keywords\n",
    "            keywords = []\n",
    "            if page_id in ngrams_series:\n",
    "                for item in ngrams_series.loc[page_id]:\n",
    "                    #doc.add_term(u\"K\" + item.lower())\n",
    "                    doc.add_term(item.lower())\n",
    "            else:\n",
    "                print(\"No keywords found for page_id={}\".format(page_id))\n",
    "\n",
    "            # save additional data\n",
    "            data = dict(\n",
    "                page_id = page_id,\n",
    "                shard = shard,\n",
    "                text = sentences_series.loc[page_id],\n",
    "                #keywords = keywords,\n",
    "            )\n",
    "            doc.set_data(json.dumps(data))\n",
    "\n",
    "            db.replace_document(idterm, doc)\n",
    "        except Exception as e:\n",
    "            print(page_id, text, e)\n",
    "db.commit()\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UUID = f8fab680-224e-426c-9efe-cd5abea8d234\r\n",
      "number of documents = 5378626\r\n",
      "average document length = 205.718\r\n",
      "document length lower bound = 1\r\n",
      "document length upper bound = 69924\r\n",
      "highest document id ever used = 5378626\r\n",
      "has positional information = true\r\n",
      "revision = 538\r\n",
      "currently open for writing = false\r\n"
     ]
    }
   ],
   "source": [
    "!xapian-delve $DBPATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for record #3129:\r\n",
      "{\"page_id\": \"11th_Gemini_Awards\", \"shard\": \"001\", \"text\": [{\"sent_id\": 0, \"text\": \"The 11th Gemini Awards was held on June 6 , 1997 , to honour achievements in Canadian television .\"}, {\"sent_id\": 1, \"text\": \"It was hosted by Albert Schultz , and was broadcast on CBC .\"}]}\r\n",
      "Term List for record #3129: 11th 11th_gemini 1997 1997_honour 6 6_1997 Q11th_Gemini_Awards Zachiev Zalbert Zand Zaward Zbroadcast Zby Zcanadian Zcbc Zgemini Zheld Zhonour Zhost Zin Zit Zjune Zon Zschultz Ztelevis Zthe Zto Zwas achievements achievements_canadian albert albert_schultz and awards awards_june broadcast broadcast_cbc by canadian canadian_television cbc gemini gemini_awards held honour honour_achievements hosted in it june june_6 on schultz schultz_broadcast television the to was\r\n"
     ]
    }
   ],
   "source": [
    "!xapian-delve -r 3129 -d $DBPATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
