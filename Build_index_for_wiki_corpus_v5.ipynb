{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import json\n",
    "from zipfile import ZipFile\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import xapian\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DBPATH = \"sentence_index\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(DBPATH):\n",
    "    os.mkdir(DBPATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "zf = ZipFile(\"wiki-pages-text.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(110, 'wiki-pages-text/wiki-009.txt')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = [item.filename for item in zf.filelist]\n",
    "len(files), files[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_shard(zf, path):\n",
    "    items = []\n",
    "    fp = zf.open(path, mode='r')\n",
    "    tfp = io.TextIOWrapper(fp)\n",
    "    nlines = 0\n",
    "    for line in tfp.readlines():\n",
    "        nlines += 1\n",
    "        #line = unicodedata.normalize('NFD', line)\n",
    "        match = re.match(\"(\\S+)\\s(\\d+)\\s(.*)\\n\", line)\n",
    "        if match:\n",
    "            item = list(match.groups())\n",
    "            item[0] = unicodedata.normalize('NFD', item[0])\n",
    "            items.append(item)\n",
    "        else:\n",
    "            #print(line)\n",
    "            pass\n",
    "    fp.close()\n",
    "    tfp.close()\n",
    "    return items#, nlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def page_id_to_text(page_id):\n",
    "        page_id = re.sub(\"(-LRB-|-LSB-|-RRB-|-RSB-)\", \"\", page_id)\n",
    "        page_id = re.sub(\"_\", \" \", page_id)\n",
    "        return page_id\n",
    "    \n",
    "def read_shard_as_df(zf, path):\n",
    "    items = read_shard(zf, path)\n",
    "    raw_df = pd.DataFrame(data=items, columns=['page_id', 'sentence', 'text'])\n",
    "    raw_df['sentence'] = raw_df.sentence.astype(int)\n",
    "    raw_df['topic'] = raw_df.page_id.apply(page_id_to_text)\n",
    "    raw_df['sentence_tokens_count'] = raw_df.text.apply(lambda x: len(x.split(' ')))\n",
    "    func = lambda x: len([item for item in x.split(\" \") if item.isalnum()])\n",
    "    raw_df['sentence_words_count'] = raw_df.text.apply(func)\n",
    "    return raw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [8:31:19<00:00, 342.26s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 32min 30s, sys: 5h 11min 10s, total: 6h 43min 40s\n",
      "Wall time: 8h 31min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Create or open the database we're going to be writing to.\n",
    "db = xapian.WritableDatabase(DBPATH, xapian.DB_CREATE_OR_OPEN)\n",
    "\n",
    "# Set up a TermGenerator that we'll use in indexing.\n",
    "termgenerator = xapian.TermGenerator()\n",
    "termgenerator.set_stemmer(xapian.Stem(\"en\"))\n",
    "\n",
    "\n",
    "\n",
    "for path in tqdm(sorted(files[1:])[10:]):\n",
    "    shard = \"\"\n",
    "    m = re.match(\".*wiki-(\\d+).*\", path)\n",
    "    if m: shard = m.groups()[0]\n",
    "    # print(path)\n",
    "    \n",
    "    sentences_df = read_shard_as_df(zf, path)\n",
    "    mask = (sentences_df.sentence_tokens_count < 5) | \\\n",
    "            (sentences_df.sentence_tokens_count > 110) | \\\n",
    "            (sentences_df.sentence_words_count < 4)  | \\\n",
    "            ((sentences_df.sentence_words_count < 10) & \\\n",
    "                (1. * sentences_df.sentence_words_count / sentences_df.sentence_tokens_count < 0.3) )\n",
    "    mask.sum()\n",
    "    sentences_df = sentences_df[~mask]\n",
    "\n",
    "    for page_id, sent_id, text, topic, _, _ in sentences_df.values:\n",
    "        try:\n",
    "            # We make a document and tell the term generator to use this.\n",
    "            doc = xapian.Document()\n",
    "            termgenerator.set_document(doc)\n",
    "\n",
    "            # Index fields without prefixes for general search.\n",
    "            termgenerator.index_text(\"{} {}\".format(topic, text))\n",
    "            termgenerator.increase_termpos()\n",
    "\n",
    "            # We use the identifier to ensure each object ends up in the\n",
    "            # database only once no matter how many times we run the\n",
    "            # indexer.\n",
    "            idterm = u\"Q{}_{}\".format(page_id, sent_id)\n",
    "            doc.add_boolean_term(idterm)\n",
    "            \n",
    "            # Index each field with a suitable prefix.\n",
    "            #termgenerator.index_text(topic, 1, 'S')\n",
    "\n",
    "            # save additional data\n",
    "            data = dict(\n",
    "                page_id = page_id,\n",
    "                sentence_id = sent_id,\n",
    "                shard = shard,\n",
    "                text = text,\n",
    "                topic = topic\n",
    "            )\n",
    "            doc.set_data(json.dumps(data))\n",
    "\n",
    "            db.replace_document(idterm, doc)\n",
    "        except Exception as e:\n",
    "            print(page_id, text, e)\n",
    "db.commit()\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UUID = 2e417945-ee51-4683-9012-a84c3edeb1a1\r\n",
      "number of documents = 23931434\r\n",
      "average document length = 43.0649\r\n",
      "document length lower bound = 6\r\n",
      "document length upper bound = 297\r\n",
      "highest document id ever used = 23931434\r\n",
      "has positional information = true\r\n",
      "revision = 2412\r\n",
      "currently open for writing = false\r\n"
     ]
    }
   ],
   "source": [
    "!xapian-delve $DBPATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for record #31029:\r\n",
      "{\"page_id\": \"1892_Princeton_Tigers_football_team\", \"sentence_id\": 0, \"shard\": \"001\", \"text\": \"The 1892 Princeton Tigers football team represented Princeton University in the 1892 college football season .\", \"topic\": \"1892 Princeton Tigers football team\"}\r\n",
      "Term List for record #31029: 1892 Q1892_Princeton_Tigers_football_team_0 Zcolleg Zfootbal Zin Zprinceton Zrepres Zseason Zteam Zthe Ztiger Zunivers college football in princeton represented season team the tigers university\r\n"
     ]
    }
   ],
   "source": [
    "!xapian-delve -r 31029 -d $DBPATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
