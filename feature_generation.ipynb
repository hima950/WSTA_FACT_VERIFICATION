{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import en_core_web_sm\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utils "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseTask():\n",
    "    def __init__(self):\n",
    "        self.nlp = en_core_web_sm.load()\n",
    "        \n",
    "    def get_POS_tags_list(self, text):\n",
    "        docs = self.nlp(text)\n",
    "        pos_list = []\n",
    "        for word in docs:\n",
    "            pos_list.append((word.text,word.pos_))\n",
    "\n",
    "        return pos_list\n",
    "    def get_enitities_list(self, text):\n",
    "        docs = nlp(text)\n",
    "        entities_dict = {word: word.label_ for word in docs.ents}\n",
    "        return entities_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PosCountsTask(BaseTask):\n",
    "    def __init__(self,df):\n",
    "        self.df = df\n",
    "        self.desired_pos = [\"NOUN\", \"PROPN\", \"VERB\", \"ADJ\"]\n",
    "        self.grammar_pos = [\"INTJ\", \"CCONJ\", \"AUX\", \"PUNCT\",\"PART\",\"SCONJ\",\"DET\",\"SYM\", \"NUM\"]\n",
    "        super().__init__()\n",
    "        \n",
    "    def make_pos_counts(self, text, pos_tag):\n",
    "        docs = self.nlp(text)\n",
    "        counts = Counter()\n",
    "        for word in docs:\n",
    "            counts[word.pos_] += 1\n",
    "        # combine all counts of other grammar words than the desired list\n",
    "        counts2 = Counter()\n",
    "        for pos in counts.keys():\n",
    "            if pos in self.grammar_pos:\n",
    "                counts2[\"other_pos_counts\"] += counts[pos]\n",
    "        \n",
    "        if pos_tag in counts2.keys():\n",
    "            return counts2[pos_tag]\n",
    "        elif pos_tag in counts.keys():\n",
    "            return counts[pos_tag]\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    def make_counts_fields(self):\n",
    "        df = self.df\n",
    "        for pos in self.desired_pos:\n",
    "            field_name = spacy.explain(pos) + \"_counts\"\n",
    "            df[field_name] = df[\"claim\"].apply(lambda x: self.make_pos_counts(x,pos))\n",
    "            \n",
    "        df[\"other_pos_counts\"] = self.df[\"claim\"].apply(lambda x: \n",
    "                                                           self.make_pos_counts(x,\"other_pos_counts\"))\n",
    "        return df\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KeywordsAndEntityTask(BaseTask):\n",
    "    def __init__(self,df):\n",
    "        self.df = df\n",
    "        self.key_pos = [\"NOUN\", \"PROPN\", \"SYM\", \"NUM\",\"ADJ\"]\n",
    "        super().__init__()\n",
    "        \n",
    "    def extract_keyword_list(self, claim):\n",
    "        # Pick all the Entities and the key POS in the list \n",
    "\n",
    "        ents = self.get_enitities_list(claim)\n",
    "\n",
    "        pos = self.get_POS_tags_list(claim)\n",
    "\n",
    "        pos_filtered = [(key,value) for key,value in pos if value in self.key_pos]\n",
    "\n",
    "        ents_list = list(ents.keys())\n",
    "        ents_list = [str(item) for item in ents_list]\n",
    "        # pos list of the entities\n",
    "        pos_of_ents = get_POS_tags_list(\" \".join(ents_list))\n",
    "        pos_of_ents = [key for key,value in pos_of_ents]\n",
    "        # list of all filtered pos\n",
    "        pos_list = [key for key,value in pos_filtered] \n",
    "        # keywords not in entities\n",
    "        other_keywords = [word for word in pos_list if word not in pos_of_ents]\n",
    "\n",
    "        final_key_words = ents_list + other_keywords\n",
    "        return final_key_words\n",
    "    \n",
    "    def caliculate_keywords_len(self):\n",
    "        df = self.df\n",
    "        \n",
    "        df[\"keyword_count\"] = df[\"claim\"].apply(lambda x: len(self.extract_keyword_list(x)))\n",
    "        return df \n",
    "    \n",
    "    def keywords_similarity(self, claim, candidate_sent):\n",
    "        # caliculate similarity b/w claim and candidate sentence using only thier key words\n",
    "        clm = self.nlp(\" \".join(self.extract_keyword_list(claim)))\n",
    "        evdc = self.nlp(\" \".join(self.extract_keyword_list(candidate_sent)))\n",
    "        return clm.similarity(evdc)\n",
    "        \n",
    "    def common_keywords_count(self, claim, candidate_sent):\n",
    "        clm = [item.lower().strip() for item in self.extract_keyword_list(claim)]\n",
    "        evdc = [item.lower().strip() for item in self.extract_keyword_list(candidate_sent)]\n",
    "        return len(list(set(evdc).intersection(clm)))\n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the Train data and add support len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "file = 'devset.json'\n",
    "with open(file) as train_file:\n",
    "    dict_train = json.load(train_file)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "new_train_dict = {}\n",
    "for key,value in dict_train.items():\n",
    "    value[\"Support_length\"] = len(value['evidence'])\n",
    "    new_train_dict[key] = value"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "with open('dev_train_1.json',\"w\") as train_file:\n",
    "    json.dump(new_train_dict, train_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_json('dev_train_1.json', orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5001, 4)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Support_length</th>\n",
       "      <th>claim</th>\n",
       "      <th>evidence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>228344</th>\n",
       "      <td>0</td>\n",
       "      <td>Island Records is a music school.</td>\n",
       "      <td>[]</td>\n",
       "      <td>NOT ENOUGH INFO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228348</th>\n",
       "      <td>0</td>\n",
       "      <td>Island Records was reviewed by Chris Blackwell.</td>\n",
       "      <td>[]</td>\n",
       "      <td>NOT ENOUGH INFO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228349</th>\n",
       "      <td>0</td>\n",
       "      <td>Island Records was founded by an American singer Graeme Goodall.</td>\n",
       "      <td>[]</td>\n",
       "      <td>NOT ENOUGH INFO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228431</th>\n",
       "      <td>0</td>\n",
       "      <td>The Wallace (poem) was written by an English person.</td>\n",
       "      <td>[]</td>\n",
       "      <td>NOT ENOUGH INFO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228432</th>\n",
       "      <td>1</td>\n",
       "      <td>The Wallace (poem) is historically accurate.</td>\n",
       "      <td>[[The_Wallace_-LRB-poem-RRB-, 2]]</td>\n",
       "      <td>REFUTES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229305</th>\n",
       "      <td>3</td>\n",
       "      <td>A working animal is incapable of being trained.</td>\n",
       "      <td>[[Working_animal, 0], [Working_animal, 1], [Working_animal, 21]]</td>\n",
       "      <td>REFUTES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229312</th>\n",
       "      <td>1</td>\n",
       "      <td>A working animal is wild only.</td>\n",
       "      <td>[[Working_animal, 0]]</td>\n",
       "      <td>REFUTES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229316</th>\n",
       "      <td>0</td>\n",
       "      <td>A working animal is trained to perform life saving tasks.</td>\n",
       "      <td>[]</td>\n",
       "      <td>NOT ENOUGH INFO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229317</th>\n",
       "      <td>1</td>\n",
       "      <td>A working animal is anything but an animal.</td>\n",
       "      <td>[[Working_animal, 0]]</td>\n",
       "      <td>REFUTES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229319</th>\n",
       "      <td>1</td>\n",
       "      <td>A working animal is a living thing.</td>\n",
       "      <td>[[Working_animal, 0]]</td>\n",
       "      <td>SUPPORTS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Support_length  \\\n",
       "228344               0   \n",
       "228348               0   \n",
       "228349               0   \n",
       "228431               0   \n",
       "228432               1   \n",
       "229305               3   \n",
       "229312               1   \n",
       "229316               0   \n",
       "229317               1   \n",
       "229319               1   \n",
       "\n",
       "                                                                   claim  \\\n",
       "228344                                 Island Records is a music school.   \n",
       "228348                   Island Records was reviewed by Chris Blackwell.   \n",
       "228349  Island Records was founded by an American singer Graeme Goodall.   \n",
       "228431              The Wallace (poem) was written by an English person.   \n",
       "228432                      The Wallace (poem) is historically accurate.   \n",
       "229305                   A working animal is incapable of being trained.   \n",
       "229312                                    A working animal is wild only.   \n",
       "229316         A working animal is trained to perform life saving tasks.   \n",
       "229317                       A working animal is anything but an animal.   \n",
       "229319                               A working animal is a living thing.   \n",
       "\n",
       "                                                                evidence  \\\n",
       "228344                                                                []   \n",
       "228348                                                                []   \n",
       "228349                                                                []   \n",
       "228431                                                                []   \n",
       "228432                                 [[The_Wallace_-LRB-poem-RRB-, 2]]   \n",
       "229305  [[Working_animal, 0], [Working_animal, 1], [Working_animal, 21]]   \n",
       "229312                                             [[Working_animal, 0]]   \n",
       "229316                                                                []   \n",
       "229317                                             [[Working_animal, 0]]   \n",
       "229319                                             [[Working_animal, 0]]   \n",
       "\n",
       "                  label  \n",
       "228344  NOT ENOUGH INFO  \n",
       "228348  NOT ENOUGH INFO  \n",
       "228349  NOT ENOUGH INFO  \n",
       "228431  NOT ENOUGH INFO  \n",
       "228432          REFUTES  \n",
       "229305          REFUTES  \n",
       "229312          REFUTES  \n",
       "229316  NOT ENOUGH INFO  \n",
       "229317          REFUTES  \n",
       "229319         SUPPORTS  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.sort_index().tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pos_counts = PosCountsTask(df=train_df)\n",
    "df = pos_counts.make_counts_fields()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"initial_features-devset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "key_counts = KeywordsAndEntityTask(df=df)\n",
    "df = key_counts.caliculate_keywords_len()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_counts = KeywordsAndEntityTask(df=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "claim = \"Chris Hemsworth appeared in A Perfect Getaway.\"\n",
    "evidence = \"Hemsworth has also appeared in the science fiction action film Star Trek -LRB- 2009 -RRB- , the thriller adventure A Perfect Getaway -LRB- 2009 -RRB- , the horror comedy The Cabin in the Woods -LRB- 2012 -RRB- , the dark-fantasy action film Snow White and the Huntsman -LRB- 2012 -RRB- , the war film Red Dawn -LRB- 2012 -RRB- , and the biographical sports drama film Rush -LRB- 2013 -RRB- .\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5100020158785087"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_counts.keywords_similarity(claim,evidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_counts.common_keywords_count(claim,evidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Chris Hemsworth', 'Perfect', 'Getaway']"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_counts.extract_keyword_list(claim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('A', 'DET'),\n",
       " ('working', 'VERB'),\n",
       " ('animal', 'NOUN'),\n",
       " ('is', 'VERB'),\n",
       " ('incapable', 'ADJ'),\n",
       " ('of', 'ADP'),\n",
       " ('being', 'VERB'),\n",
       " ('trained', 'VERB'),\n",
       " ('.', 'PUNCT')]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_counts.get_POS_tags_list(\"A working animal is incapable of being trained.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
