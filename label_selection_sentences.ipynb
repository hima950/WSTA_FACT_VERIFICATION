{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "NOTE: All Readme and instruction for running code is on github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import random\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the concated DATASET For Label Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_label_test_df = pd.DataFrame(cols)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv(\"train_labels_evd_concated.csv\")\n",
    "\n",
    "train_df.head()\n",
    "\n",
    "train_df['len'] = train_df.evidence.apply(lambda x : len(x.split()))\n",
    "\n",
    "mask = train_df['len'] < 230\n",
    "\n",
    "df = train_df[mask]\n",
    "\n",
    "train_df.shape\n",
    "\n",
    "df.label.value_counts()\n",
    "\n",
    "df[\"label\"] = df.label.apply(lambda x: 1 if x==\"SUPPORTS\" else 0)\n",
    "\n",
    "df.label.value_counts()\n",
    "\n",
    "sup = df[df[\"label\"]==1].sample(25000,random_state=123)\n",
    "ref = df[df[\"label\"]==0].sample(25000,random_state=12)\n",
    "df_1 = pd.concat([sup,ref])\n",
    "\n",
    "X = df[[\"claim\",\"evidence\"]]\n",
    "y = df[\"label\"]\n",
    "\n",
    " Below code is only for reducing the training dataset size for faster training \n",
    "\n",
    "X.shape\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X, X_test, y, y_test = train_test_split(X, y,\n",
    "                                        stratify=y, \n",
    "                                        test_size=0.40)\n",
    "\n",
    "X.shape\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    stratify=y, \n",
    "                                                    test_size=0.2)\n",
    "\n",
    "X_train, X_dev, y_train, y_dev = train_test_split(X_train, y_train,\n",
    "                                                    stratify=y_train, \n",
    "                                                    test_size=0.22)\n",
    "\n",
    "train = pd.DataFrame()\n",
    "train[[\"claim\",\"evidence\"]] = X_train\n",
    "train[\"label\"] = y_train\n",
    "dev = pd.DataFrame()\n",
    "dev[[\"claim\",\"evidence\"]] = X_dev\n",
    "dev[\"label\"] = y_dev\n",
    "test = pd.DataFrame()\n",
    "test[[\"claim\",\"evidence\"]] = X_test\n",
    "test[\"label\"] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('./bert/lb_data/test.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.reset_index()\n",
    "dev = dev.reset_index()\n",
    "test = test.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['index', 'claim', 'evidence','label']\n",
    "rename = {'label':\"label\", \"claim\":\"sentence1\",\"evidence\":\"sentence2\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[columns]\n",
    "dev = dev[columns]\n",
    "test = test[[\"index\",'claim', 'evidence']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.rename(columns=rename,inplace=True)\n",
    "dev.rename(columns=rename,inplace=True)\n",
    "test.rename(columns=rename,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('./bert/lb_data/train.tsv', sep='\\t', index=False, header=True)\n",
    "dev.to_csv('./bert/lb_data/dev.tsv', sep='\\t', index=False, header=True)\n",
    "test.to_csv('./bert/lb_data/test.tsv', sep='\\t', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19799</td>\n",
       "      <td>Vincente Minnelli is a director.</td>\n",
       "      <td>In addition to having directed some of the mos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>108998</td>\n",
       "      <td>Led Zeppelin released an eponymous debut album...</td>\n",
       "      <td>Led Zeppelin is the eponymous debut studio alb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84949</td>\n",
       "      <td>Gerard Lee directs.</td>\n",
       "      <td>Gerard Lee -LRB- born 1951 in Melbourne -RRB- ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14019</td>\n",
       "      <td>Just My Luck (2006 film) features an American ...</td>\n",
       "      <td>Following Just My Luck , Lohan focused on smal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31112</td>\n",
       "      <td>Odin travels independently only.</td>\n",
       "      <td>He is often accompanied by his animal companio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index                                          sentence1  \\\n",
       "0   19799                   Vincente Minnelli is a director.   \n",
       "1  108998  Led Zeppelin released an eponymous debut album...   \n",
       "2   84949                                Gerard Lee directs.   \n",
       "3   14019  Just My Luck (2006 film) features an American ...   \n",
       "4   31112                   Odin travels independently only.   \n",
       "\n",
       "                                           sentence2  \n",
       "0  In addition to having directed some of the mos...  \n",
       "1  Led Zeppelin is the eponymous debut studio alb...  \n",
       "2  Gerard Lee -LRB- born 1951 in Melbourne -RRB- ...  \n",
       "3  Following Just My Luck , Lohan focused on smal...  \n",
       "4  He is often accompanied by his animal companio...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60981</td>\n",
       "      <td>Snow White and the Seven Dwarfs (1937 film) is...</td>\n",
       "      <td>It was a critical and commercial success , and...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60976</td>\n",
       "      <td>Doug Jones starred in a 2017 science fiction h...</td>\n",
       "      <td>He has appeared in films such as Tank Girl , H...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36040</td>\n",
       "      <td>Slash exclusively played country music.</td>\n",
       "      <td>Velvet Revolver was an American hard rock supe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80297</td>\n",
       "      <td>Tommy Chong was born on May 23rd, 1938.</td>\n",
       "      <td>Thomas B. Kin Chong -LRB- born May 24 , 1938 -...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84695</td>\n",
       "      <td>Johan Heldenbergh starred in The Zookeepers Wife.</td>\n",
       "      <td>He gained international fame by starring in fi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                          sentence1  \\\n",
       "0  60981  Snow White and the Seven Dwarfs (1937 film) is...   \n",
       "1  60976  Doug Jones starred in a 2017 science fiction h...   \n",
       "2  36040            Slash exclusively played country music.   \n",
       "3  80297            Tommy Chong was born on May 23rd, 1938.   \n",
       "4  84695  Johan Heldenbergh starred in The Zookeepers Wife.   \n",
       "\n",
       "                                           sentence2  label  \n",
       "0  It was a critical and commercial success , and...      0  \n",
       "1  He has appeared in films such as Tank Girl , H...      1  \n",
       "2  Velvet Revolver was an American hard rock supe...      0  \n",
       "3  Thomas B. Kin Chong -LRB- born May 24 , 1938 -...      0  \n",
       "4  He gained international fame by starring in fi...      1  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_o = pd.read_csv('./bert/lb_data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claim</th>\n",
       "      <th>evidence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vincente Minnelli is a director.</td>\n",
       "      <td>In addition to having directed some of the mos...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Led Zeppelin released an eponymous debut album...</td>\n",
       "      <td>Led Zeppelin is the eponymous debut studio alb...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gerard Lee directs.</td>\n",
       "      <td>Gerard Lee -LRB- born 1951 in Melbourne -RRB- ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Just My Luck (2006 film) features an American ...</td>\n",
       "      <td>Following Just My Luck , Lohan focused on smal...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Odin travels independently only.</td>\n",
       "      <td>He is often accompanied by his animal companio...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               claim  \\\n",
       "0                   Vincente Minnelli is a director.   \n",
       "1  Led Zeppelin released an eponymous debut album...   \n",
       "2                                Gerard Lee directs.   \n",
       "3  Just My Luck (2006 film) features an American ...   \n",
       "4                   Odin travels independently only.   \n",
       "\n",
       "                                            evidence  label  \n",
       "0  In addition to having directed some of the mos...      1  \n",
       "1  Led Zeppelin is the eponymous debut studio alb...      0  \n",
       "2  Gerard Lee -LRB- born 1951 in Melbourne -RRB- ...      1  \n",
       "3  Following Just My Luck , Lohan focused on smal...      1  \n",
       "4  He is often accompanied by his animal companio...      0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_o.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(test_o.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = pd.read_csv('./bert/lb_bert_output/test_results.tsv', sep='\\t',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.argmax(np.array(test_pred[[0,1]]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9378151260504202\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.88      0.88      2580\n",
      "           1       0.96      0.96      0.96      6940\n",
      "\n",
      "    accuracy                           0.94      9520\n",
      "   macro avg       0.92      0.92      0.92      9520\n",
      "weighted avg       0.94      0.94      0.94      9520\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('accuracy: {}'.format(accuracy_score(np.array(test_o.label), y_pred)))\n",
    "print(classification_report(np.array(test_o.label), y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# actual test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'test-unlabelled.json'\n",
    "with open(file) as train_file:\n",
    "    test = json.load(train_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"test_pred_top13.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = []\n",
    "for key, item in tqdm(test.items()):\n",
    "    evd_lst = df[df.claim_id == int(key)].evidence.to_list()\n",
    "    if len(evd_lst) > 5:\n",
    "        evd_lst = evd_lst[:4]\n",
    "    if evd_lst:\n",
    "        d = {}\n",
    "        d[\"claim_id\"] = key\n",
    "        d[\"claim\"] = item[\"claim\"]\n",
    "        evd_txt = \" \".join(evd_lst)\n",
    "        d[\"evidence\"] = evd_txt\n",
    "        cols.append(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is Actual Test Part \n",
    "run from here to get predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('final_test_df_top13.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9463, 3)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[\"words_len\"] = test_df[\"evidence\"].apply(lambda x : len(x.split()))\n",
    "\n",
    "mask2 = (test_df[\"words_len\"] <= 250)\n",
    "test_df = test_df[mask2]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "mask = (test_df[\"rank\"] <= 7)\n",
    "test_df = test_df[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9463, 4)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[\"evidence\"] = test_df[\"evidence\"].apply(lambda x: x.replace(\"\\n\",\"\").strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['claim', 'claim_id', 'evidence', 'words_len'], dtype='object')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df[['claim_id', 'claim', 'evidence']].rename(columns={\"claim_id\":\"index\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv('./bert/data/test.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test_df = test_df.rename(columns={\"ID\":\"id\"})"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test_df[\"id1\"] = test_df.id\n",
    "test_df[\"index\"] =test_df.index"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "columns = [\"index\",'id',\"id1\",'claim', 'evidence']\n",
    "rename = {'label':\"Quality\",\"id\":\"#1 ID\",\"id1\":\"#2 ID\",\"claim\":\"#1 String\",\"evidence\":\"#2 String\"}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test_df = test_df[columns]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test_df.rename(columns=rename,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9463, 3)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv('./bert/data/test.tsv', sep='\\t', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9463, 3)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>claim</th>\n",
       "      <th>evidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>110000</td>\n",
       "      <td>Raven-Symoné is an Anglican.</td>\n",
       "      <td>Raven-Symoné Christina Pearman -LRB- -LSB- ˈre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16079</td>\n",
       "      <td>Solanum contains plants with ornamental flowers.</td>\n",
       "      <td>It also contains the nightshades and horse net...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>126871</td>\n",
       "      <td>The Icelandic Coast Guard is also known as Gae...</td>\n",
       "      <td>Iceland 's own defense of its territorial wate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>226458</td>\n",
       "      <td>Chadwick Boseman portrayed a film character.</td>\n",
       "      <td>Chadwick Aaron Boseman -LRB- born November 29 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51263</td>\n",
       "      <td>James Brolin is an orthodontist.</td>\n",
       "      <td>Josh James Brolin -LRB- -LSB- ˈbroʊlᵻn -RSB- b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index                                              claim  \\\n",
       "0  110000                       Raven-Symoné is an Anglican.   \n",
       "1   16079   Solanum contains plants with ornamental flowers.   \n",
       "2  126871  The Icelandic Coast Guard is also known as Gae...   \n",
       "3  226458       Chadwick Boseman portrayed a film character.   \n",
       "4   51263                   James Brolin is an orthodontist.   \n",
       "\n",
       "                                            evidence  \n",
       "0  Raven-Symoné Christina Pearman -LRB- -LSB- ˈre...  \n",
       "1  It also contains the nightshades and horse net...  \n",
       "2  Iceland 's own defense of its territorial wate...  \n",
       "3  Chadwick Aaron Boseman -LRB- born November 29 ...  \n",
       "4  Josh James Brolin -LRB- -LSB- ˈbroʊlᵻn -RSB- b...  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2394\n",
       "0    1155\n",
       "Name: Quality, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mr.Quality.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./bert/data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9463, 3)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_o = pd.read_csv('./bert/data/test.csv')\n",
    "\n",
    "test_pred = pd.read_csv('./bert/lb_bert_output/test_results.tsv', sep='\\t',header=None)\n",
    "\n",
    "y_pred = np.argmax(np.array(test_pred[[0,1]]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_o[\"label\"] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_o['label'] = test_o.label.apply(lambda x: \"SUPPORTS\" if x==1 else \"REFUTES\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9463"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_o[\"index\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>claim</th>\n",
       "      <th>evidence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>110000</td>\n",
       "      <td>Raven-Symoné is an Anglican.</td>\n",
       "      <td>Raven-Symoné Christina Pearman -LRB- -LSB- ˈre...</td>\n",
       "      <td>REFUTES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16079</td>\n",
       "      <td>Solanum contains plants with ornamental flowers.</td>\n",
       "      <td>It also contains the nightshades and horse net...</td>\n",
       "      <td>SUPPORTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>126871</td>\n",
       "      <td>The Icelandic Coast Guard is also known as Gae...</td>\n",
       "      <td>Iceland 's own defense of its territorial wate...</td>\n",
       "      <td>SUPPORTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>226458</td>\n",
       "      <td>Chadwick Boseman portrayed a film character.</td>\n",
       "      <td>Chadwick Aaron Boseman -LRB- born November 29 ...</td>\n",
       "      <td>SUPPORTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51263</td>\n",
       "      <td>James Brolin is an orthodontist.</td>\n",
       "      <td>Josh James Brolin -LRB- -LSB- ˈbroʊlᵻn -RSB- b...</td>\n",
       "      <td>REFUTES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index                                              claim  \\\n",
       "0  110000                       Raven-Symoné is an Anglican.   \n",
       "1   16079   Solanum contains plants with ornamental flowers.   \n",
       "2  126871  The Icelandic Coast Guard is also known as Gae...   \n",
       "3  226458       Chadwick Boseman portrayed a film character.   \n",
       "4   51263                   James Brolin is an orthodontist.   \n",
       "\n",
       "                                            evidence     label  \n",
       "0  Raven-Symoné Christina Pearman -LRB- -LSB- ˈre...   REFUTES  \n",
       "1  It also contains the nightshades and horse net...  SUPPORTS  \n",
       "2  Iceland 's own defense of its territorial wate...  SUPPORTS  \n",
       "3  Chadwick Aaron Boseman -LRB- born November 29 ...  SUPPORTS  \n",
       "4  Josh James Brolin -LRB- -LSB- ˈbroʊlᵻn -RSB- b...   REFUTES  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_o.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SUPPORTS    4962\n",
       "REFUTES     4501\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_o.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9463"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4962+4501"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_o.to_csv(\"test_pred_final_labels.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_discard_samples = 1\n",
    "# split fields by tabs\n",
    "field_separator = nlp.data.Splitter(',')\n",
    "# fields to select from the file\n",
    "field_indices = [1, 2, 0]\n",
    "data_train_raw = nlp.data.TSVDataset(filename=\"sample.tsv\",\n",
    "                                     field_separator=field_separator,\n",
    "                                     num_discard_samples=num_discard_samples,\n",
    "                                     field_indices=field_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# use the vocabulary from pre-trained model for tokenization\n",
    "bert_tokenizer = nlp.data.BERTTokenizer(vocabulary, lower=True)\n",
    "# maximum sequence length\n",
    "max_len = 128\n",
    "# the labels for the two classes\n",
    "all_labels = [\"0\", \"1\"]\n",
    "# whether to transform the data as sentence pairs.\n",
    "# for single sentence classification, set pair=False\n",
    "pair = True\n",
    "transform = dataset.BERTDatasetTransform(bert_tokenizer, max_len,\n",
    "                                         class_labels=all_labels,\n",
    "                                         pad=True,\n",
    "                                         pair=pair)\n",
    "data_train = data_train_raw.transform(transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary used for tokenization = \n",
      "Vocab(size=30522, unk=\"[UNK]\", reserved=\"['[PAD]', '[CLS]', '[SEP]', '[MASK]']\")\n",
      "[PAD] token id = 1\n",
      "[CLS] token id = 2\n",
      "[SEP] token id = 3\n"
     ]
    }
   ],
   "source": [
    "print('vocabulary used for tokenization = \\n%s'%vocabulary)\n",
    "print('%s token id = %s'%(vocabulary.padding_token, vocabulary[vocabulary.padding_token]))\n",
    "print('%s token id = %s'%(vocabulary.cls_token, vocabulary[vocabulary.cls_token]))\n",
    "print('%s token id = %s'%(vocabulary.sep_token, vocabulary[vocabulary.sep_token]))\n",
    "#print('token ids = \\n%s'%data_train[0][0])\n",
    "#print('valid length = \\n%s'%data_train[0][1])\n",
    "#print('segment ids = \\n%s'%data_train[0][2])\n",
    "#print('label = \\n%s'%data_train[0][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 4/23] loss=0.7296, lr=0.0000050, acc=0.403\n",
      "[Epoch 0 Batch 8/23] loss=0.7393, lr=0.0000050, acc=0.421\n",
      "[Epoch 0 Batch 12/23] loss=0.6914, lr=0.0000050, acc=0.425\n",
      "[Epoch 0 Batch 16/23] loss=0.7459, lr=0.0000050, acc=0.406\n",
      "[Epoch 0 Batch 20/23] loss=0.7003, lr=0.0000050, acc=0.408\n",
      "[Epoch 1 Batch 4/23] loss=0.6891, lr=0.0000050, acc=0.439\n",
      "[Epoch 1 Batch 8/23] loss=0.7181, lr=0.0000050, acc=0.424\n",
      "[Epoch 1 Batch 12/23] loss=0.6778, lr=0.0000050, acc=0.493\n",
      "[Epoch 1 Batch 16/23] loss=0.7571, lr=0.0000050, acc=0.482\n",
      "[Epoch 1 Batch 20/23] loss=0.7081, lr=0.0000050, acc=0.500\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "lr = 5e-6\n",
    "train_sampler = nlp.data.FixedBucketSampler(lengths=[int(item[1]) for item in data_train],\n",
    "                                            batch_size=batch_size,\n",
    "                                            shuffle=True)\n",
    "bert_dataloader = mx.gluon.data.DataLoader(data_train, batch_sampler=train_sampler)\n",
    "\n",
    "trainer = gluon.Trainer(model.collect_params(), 'adam',\n",
    "                        {'learning_rate': lr, 'epsilon': 1e-9})\n",
    "\n",
    "# collect all differentiable parameters\n",
    "# grad_req == 'null' indicates no gradients are calculated (e.g. constant parameters)\n",
    "# the gradients for these params are clipped later\n",
    "params = [p for p in model.collect_params().values() if p.grad_req != 'null']\n",
    "grad_clip = 1\n",
    "\n",
    "log_interval = 4\n",
    "num_epochs = 2\n",
    "for epoch_id in range(num_epochs):\n",
    "    metric.reset()\n",
    "    step_loss = 0\n",
    "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(bert_dataloader):\n",
    "        with mx.autograd.record():\n",
    "            \n",
    "            # load data to GPU\n",
    "            token_ids = token_ids.as_in_context(ctx)\n",
    "            valid_length = valid_length.as_in_context(ctx)\n",
    "            segment_ids = segment_ids.as_in_context(ctx)\n",
    "            label = label.as_in_context(ctx)\n",
    "            \n",
    "            # forward computation\n",
    "            out = model(token_ids, segment_ids, valid_length.astype('float32'))\n",
    "            ls = loss_function(out, label).mean()\n",
    "            \n",
    "        # backward computation\n",
    "        ls.backward()\n",
    "        \n",
    "        # gradient clipping\n",
    "        trainer.allreduce_grads()\n",
    "        nlp.utils.clip_grad_global_norm(params, 1)\n",
    "        trainer.update(1)\n",
    "\n",
    "        step_loss += ls.asscalar()\n",
    "        metric.update([label], [out])\n",
    "        if (batch_id + 1) % (log_interval) == 0:\n",
    "            print('[Epoch {} Batch {}/{}] loss={:.4f}, lr={:.7f}, acc={:.3f}'\n",
    "                         .format(epoch_id, batch_id + 1, len(bert_dataloader),\n",
    "                                 step_loss / log_interval,\n",
    "                                 trainer.learning_rate, metric.get()[1]))\n",
    "            step_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"sentence_selec.params\"\n",
    "model.save_parameters(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[ 0.3981911   0.49658114]\n",
       " [ 0.7577672   0.6063629 ]\n",
       " [ 0.7166761   0.22103053]\n",
       " [ 0.2650067   0.44527054]\n",
       " [ 0.35528415  0.22392039]\n",
       " [ 0.5406032   0.5128474 ]\n",
       " [ 0.42888275  0.414084  ]\n",
       " [-0.08531152 -0.2455985 ]\n",
       " [ 0.40655226  0.16031429]\n",
       " [ 0.50647265  0.23514538]\n",
       " [ 0.37992063  0.4750597 ]\n",
       " [ 0.40704784  0.36610222]\n",
       " [ 0.42767343  0.26796952]\n",
       " [-0.085116    0.48030224]\n",
       " [ 0.29354116  0.08990882]\n",
       " [ 0.13869387 -0.33121985]\n",
       " [ 0.25032517  0.44310197]\n",
       " [ 0.53794676  0.03402577]\n",
       " [ 0.182645    0.48537406]\n",
       " [ 0.4527117   0.41433826]\n",
       " [ 0.19860749  0.2618924 ]\n",
       " [ 1.0135635   0.17335409]\n",
       " [ 0.07016656 -0.25789693]\n",
       " [ 0.44446617  0.60822994]\n",
       " [ 0.5225667   0.35670865]\n",
       " [ 0.92044586  0.26600736]\n",
       " [ 0.28044128  0.23549686]\n",
       " [ 0.34756947  0.33452037]\n",
       " [ 0.08498111  0.40884554]\n",
       " [ 0.30952862  0.16564724]\n",
       " [ 0.43823653  0.33737177]\n",
       " [ 0.1071428  -0.05328693]]\n",
       "<NDArray 32x2 @gpu(0)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Block.summary of BERTClassifier(\n",
       "  (classifier): HybridSequential(\n",
       "    (0): Dropout(p = 0.1, axes=())\n",
       "    (1): Dense(768 -> 2, linear)\n",
       "  )\n",
       "  (bert): BERTModel(\n",
       "    (token_type_embed): HybridSequential(\n",
       "      (0): Embedding(2 -> 768, float32)\n",
       "      (1): Dropout(p = 0.1, axes=())\n",
       "    )\n",
       "    (encoder): BERTEncoder(\n",
       "      (layer_norm): BERTLayerNorm(axis=-1, scale=True, eps=1e-12, center=True, in_channels=768)\n",
       "      (transformer_cells): HybridSequential(\n",
       "        (0): BERTEncoderCell(\n",
       "          (attention_cell): MultiHeadAttentionCell(\n",
       "            (_base_cell): DotProductAttentionCell(\n",
       "              (_dropout_layer): Dropout(p = 0.1, axes=())\n",
       "            )\n",
       "            (proj_key): Dense(768 -> 768, linear)\n",
       "            (proj_query): Dense(768 -> 768, linear)\n",
       "            (proj_value): Dense(768 -> 768, linear)\n",
       "          )\n",
       "          (layer_norm): BERTLayerNorm(axis=-1, scale=True, eps=1e-12, center=True, in_channels=768)\n",
       "          (proj): Dense(768 -> 768, linear)\n",
       "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
       "          (ffn): BERTPositionwiseFFN(\n",
       "            (ffn_1): Dense(768 -> 3072, linear)\n",
       "            (activation): GELU()\n",
       "            (ffn_2): Dense(3072 -> 768, linear)\n",
       "            (layer_norm): BERTLayerNorm(axis=-1, scale=True, eps=1e-12, center=True, in_channels=768)\n",
       "            (dropout_layer): Dropout(p = 0.1, axes=())\n",
       "          )\n",
       "        )\n",
       "        (1): BERTEncoderCell(\n",
       "          (attention_cell): MultiHeadAttentionCell(\n",
       "            (_base_cell): DotProductAttentionCell(\n",
       "              (_dropout_layer): Dropout(p = 0.1, axes=())\n",
       "            )\n",
       "            (proj_key): Dense(768 -> 768, linear)\n",
       "            (proj_query): Dense(768 -> 768, linear)\n",
       "            (proj_value): Dense(768 -> 768, linear)\n",
       "          )\n",
       "          (layer_norm): BERTLayerNorm(axis=-1, scale=True, eps=1e-12, center=True, in_channels=768)\n",
       "          (proj): Dense(768 -> 768, linear)\n",
       "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
       "          (ffn): BERTPositionwiseFFN(\n",
       "            (ffn_1): Dense(768 -> 3072, linear)\n",
       "            (activation): GELU()\n",
       "            (ffn_2): Dense(3072 -> 768, linear)\n",
       "            (layer_norm): BERTLayerNorm(axis=-1, scale=True, eps=1e-12, center=True, in_channels=768)\n",
       "            (dropout_layer): Dropout(p = 0.1, axes=())\n",
       "          )\n",
       "        )\n",
       "        (2): BERTEncoderCell(\n",
       "          (attention_cell): MultiHeadAttentionCell(\n",
       "            (_base_cell): DotProductAttentionCell(\n",
       "              (_dropout_layer): Dropout(p = 0.1, axes=())\n",
       "            )\n",
       "            (proj_key): Dense(768 -> 768, linear)\n",
       "            (proj_query): Dense(768 -> 768, linear)\n",
       "            (proj_value): Dense(768 -> 768, linear)\n",
       "          )\n",
       "          (layer_norm): BERTLayerNorm(axis=-1, scale=True, eps=1e-12, center=True, in_channels=768)\n",
       "          (proj): Dense(768 -> 768, linear)\n",
       "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
       "          (ffn): BERTPositionwiseFFN(\n",
       "            (ffn_1): Dense(768 -> 3072, linear)\n",
       "            (activation): GELU()\n",
       "            (ffn_2): Dense(3072 -> 768, linear)\n",
       "            (layer_norm): BERTLayerNorm(axis=-1, scale=True, eps=1e-12, center=True, in_channels=768)\n",
       "            (dropout_layer): Dropout(p = 0.1, axes=())\n",
       "          )\n",
       "        )\n",
       "        (3): BERTEncoderCell(\n",
       "          (attention_cell): MultiHeadAttentionCell(\n",
       "            (_base_cell): DotProductAttentionCell(\n",
       "              (_dropout_layer): Dropout(p = 0.1, axes=())\n",
       "            )\n",
       "            (proj_key): Dense(768 -> 768, linear)\n",
       "            (proj_query): Dense(768 -> 768, linear)\n",
       "            (proj_value): Dense(768 -> 768, linear)\n",
       "          )\n",
       "          (layer_norm): BERTLayerNorm(axis=-1, scale=True, eps=1e-12, center=True, in_channels=768)\n",
       "          (proj): Dense(768 -> 768, linear)\n",
       "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
       "          (ffn): BERTPositionwiseFFN(\n",
       "            (ffn_1): Dense(768 -> 3072, linear)\n",
       "            (activation): GELU()\n",
       "            (ffn_2): Dense(3072 -> 768, linear)\n",
       "            (layer_norm): BERTLayerNorm(axis=-1, scale=True, eps=1e-12, center=True, in_channels=768)\n",
       "            (dropout_layer): Dropout(p = 0.1, axes=())\n",
       "          )\n",
       "        )\n",
       "        (4): BERTEncoderCell(\n",
       "          (attention_cell): MultiHeadAttentionCell(\n",
       "            (_base_cell): DotProductAttentionCell(\n",
       "              (_dropout_layer): Dropout(p = 0.1, axes=())\n",
       "            )\n",
       "            (proj_key): Dense(768 -> 768, linear)\n",
       "            (proj_query): Dense(768 -> 768, linear)\n",
       "            (proj_value): Dense(768 -> 768, linear)\n",
       "          )\n",
       "          (layer_norm): BERTLayerNorm(axis=-1, scale=True, eps=1e-12, center=True, in_channels=768)\n",
       "          (proj): Dense(768 -> 768, linear)\n",
       "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
       "          (ffn): BERTPositionwiseFFN(\n",
       "            (ffn_1): Dense(768 -> 3072, linear)\n",
       "            (activation): GELU()\n",
       "            (ffn_2): Dense(3072 -> 768, linear)\n",
       "            (layer_norm): BERTLayerNorm(axis=-1, scale=True, eps=1e-12, center=True, in_channels=768)\n",
       "            (dropout_layer): Dropout(p = 0.1, axes=())\n",
       "          )\n",
       "        )\n",
       "        (5): BERTEncoderCell(\n",
       "          (attention_cell): MultiHeadAttentionCell(\n",
       "            (_base_cell): DotProductAttentionCell(\n",
       "              (_dropout_layer): Dropout(p = 0.1, axes=())\n",
       "            )\n",
       "            (proj_key): Dense(768 -> 768, linear)\n",
       "            (proj_query): Dense(768 -> 768, linear)\n",
       "            (proj_value): Dense(768 -> 768, linear)\n",
       "          )\n",
       "          (layer_norm): BERTLayerNorm(axis=-1, scale=True, eps=1e-12, center=True, in_channels=768)\n",
       "          (proj): Dense(768 -> 768, linear)\n",
       "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
       "          (ffn): BERTPositionwiseFFN(\n",
       "            (ffn_1): Dense(768 -> 3072, linear)\n",
       "            (activation): GELU()\n",
       "            (ffn_2): Dense(3072 -> 768, linear)\n",
       "            (layer_norm): BERTLayerNorm(axis=-1, scale=True, eps=1e-12, center=True, in_channels=768)\n",
       "            (dropout_layer): Dropout(p = 0.1, axes=())\n",
       "          )\n",
       "        )\n",
       "        (6): BERTEncoderCell(\n",
       "          (attention_cell): MultiHeadAttentionCell(\n",
       "            (_base_cell): DotProductAttentionCell(\n",
       "              (_dropout_layer): Dropout(p = 0.1, axes=())\n",
       "            )\n",
       "            (proj_key): Dense(768 -> 768, linear)\n",
       "            (proj_query): Dense(768 -> 768, linear)\n",
       "            (proj_value): Dense(768 -> 768, linear)\n",
       "          )\n",
       "          (layer_norm): BERTLayerNorm(axis=-1, scale=True, eps=1e-12, center=True, in_channels=768)\n",
       "          (proj): Dense(768 -> 768, linear)\n",
       "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
       "          (ffn): BERTPositionwiseFFN(\n",
       "            (ffn_1): Dense(768 -> 3072, linear)\n",
       "            (activation): GELU()\n",
       "            (ffn_2): Dense(3072 -> 768, linear)\n",
       "            (layer_norm): BERTLayerNorm(axis=-1, scale=True, eps=1e-12, center=True, in_channels=768)\n",
       "            (dropout_layer): Dropout(p = 0.1, axes=())\n",
       "          )\n",
       "        )\n",
       "        (7): BERTEncoderCell(\n",
       "          (attention_cell): MultiHeadAttentionCell(\n",
       "            (_base_cell): DotProductAttentionCell(\n",
       "              (_dropout_layer): Dropout(p = 0.1, axes=())\n",
       "            )\n",
       "            (proj_key): Dense(768 -> 768, linear)\n",
       "            (proj_query): Dense(768 -> 768, linear)\n",
       "            (proj_value): Dense(768 -> 768, linear)\n",
       "          )\n",
       "          (layer_norm): BERTLayerNorm(axis=-1, scale=True, eps=1e-12, center=True, in_channels=768)\n",
       "          (proj): Dense(768 -> 768, linear)\n",
       "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
       "          (ffn): BERTPositionwiseFFN(\n",
       "            (ffn_1): Dense(768 -> 3072, linear)\n",
       "            (activation): GELU()\n",
       "            (ffn_2): Dense(3072 -> 768, linear)\n",
       "            (layer_norm): BERTLayerNorm(axis=-1, scale=True, eps=1e-12, center=True, in_channels=768)\n",
       "            (dropout_layer): Dropout(p = 0.1, axes=())\n",
       "          )\n",
       "        )\n",
       "        (8): BERTEncoderCell(\n",
       "          (attention_cell): MultiHeadAttentionCell(\n",
       "            (_base_cell): DotProductAttentionCell(\n",
       "              (_dropout_layer): Dropout(p = 0.1, axes=())\n",
       "            )\n",
       "            (proj_key): Dense(768 -> 768, linear)\n",
       "            (proj_query): Dense(768 -> 768, linear)\n",
       "            (proj_value): Dense(768 -> 768, linear)\n",
       "          )\n",
       "          (layer_norm): BERTLayerNorm(axis=-1, scale=True, eps=1e-12, center=True, in_channels=768)\n",
       "          (proj): Dense(768 -> 768, linear)\n",
       "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
       "          (ffn): BERTPositionwiseFFN(\n",
       "            (ffn_1): Dense(768 -> 3072, linear)\n",
       "            (activation): GELU()\n",
       "            (ffn_2): Dense(3072 -> 768, linear)\n",
       "            (layer_norm): BERTLayerNorm(axis=-1, scale=True, eps=1e-12, center=True, in_channels=768)\n",
       "            (dropout_layer): Dropout(p = 0.1, axes=())\n",
       "          )\n",
       "        )\n",
       "        (9): BERTEncoderCell(\n",
       "          (attention_cell): MultiHeadAttentionCell(\n",
       "            (_base_cell): DotProductAttentionCell(\n",
       "              (_dropout_layer): Dropout(p = 0.1, axes=())\n",
       "            )\n",
       "            (proj_key): Dense(768 -> 768, linear)\n",
       "            (proj_query): Dense(768 -> 768, linear)\n",
       "            (proj_value): Dense(768 -> 768, linear)\n",
       "          )\n",
       "          (layer_norm): BERTLayerNorm(axis=-1, scale=True, eps=1e-12, center=True, in_channels=768)\n",
       "          (proj): Dense(768 -> 768, linear)\n",
       "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
       "          (ffn): BERTPositionwiseFFN(\n",
       "            (ffn_1): Dense(768 -> 3072, linear)\n",
       "            (activation): GELU()\n",
       "            (ffn_2): Dense(3072 -> 768, linear)\n",
       "            (layer_norm): BERTLayerNorm(axis=-1, scale=True, eps=1e-12, center=True, in_channels=768)\n",
       "            (dropout_layer): Dropout(p = 0.1, axes=())\n",
       "          )\n",
       "        )\n",
       "        (10): BERTEncoderCell(\n",
       "          (attention_cell): MultiHeadAttentionCell(\n",
       "            (_base_cell): DotProductAttentionCell(\n",
       "              (_dropout_layer): Dropout(p = 0.1, axes=())\n",
       "            )\n",
       "            (proj_key): Dense(768 -> 768, linear)\n",
       "            (proj_query): Dense(768 -> 768, linear)\n",
       "            (proj_value): Dense(768 -> 768, linear)\n",
       "          )\n",
       "          (layer_norm): BERTLayerNorm(axis=-1, scale=True, eps=1e-12, center=True, in_channels=768)\n",
       "          (proj): Dense(768 -> 768, linear)\n",
       "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
       "          (ffn): BERTPositionwiseFFN(\n",
       "            (ffn_1): Dense(768 -> 3072, linear)\n",
       "            (activation): GELU()\n",
       "            (ffn_2): Dense(3072 -> 768, linear)\n",
       "            (layer_norm): BERTLayerNorm(axis=-1, scale=True, eps=1e-12, center=True, in_channels=768)\n",
       "            (dropout_layer): Dropout(p = 0.1, axes=())\n",
       "          )\n",
       "        )\n",
       "        (11): BERTEncoderCell(\n",
       "          (attention_cell): MultiHeadAttentionCell(\n",
       "            (_base_cell): DotProductAttentionCell(\n",
       "              (_dropout_layer): Dropout(p = 0.1, axes=())\n",
       "            )\n",
       "            (proj_key): Dense(768 -> 768, linear)\n",
       "            (proj_query): Dense(768 -> 768, linear)\n",
       "            (proj_value): Dense(768 -> 768, linear)\n",
       "          )\n",
       "          (layer_norm): BERTLayerNorm(axis=-1, scale=True, eps=1e-12, center=True, in_channels=768)\n",
       "          (proj): Dense(768 -> 768, linear)\n",
       "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
       "          (ffn): BERTPositionwiseFFN(\n",
       "            (ffn_1): Dense(768 -> 3072, linear)\n",
       "            (activation): GELU()\n",
       "            (ffn_2): Dense(3072 -> 768, linear)\n",
       "            (layer_norm): BERTLayerNorm(axis=-1, scale=True, eps=1e-12, center=True, in_channels=768)\n",
       "            (dropout_layer): Dropout(p = 0.1, axes=())\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (dropout_layer): Dropout(p = 0.1, axes=())\n",
       "    )\n",
       "    (pooler): Dense(768 -> 768, Activation(tanh))\n",
       "    (word_embed): HybridSequential(\n",
       "      (0): Embedding(30522 -> 768, float32)\n",
       "      (1): Dropout(p = 0.1, axes=())\n",
       "    )\n",
       "  )\n",
       ")>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net(\n",
    "    mx.nd.reshape(\n",
    "        mx.nd.array(vocab[['This', 'movie', 'is', 'amazing']], ctx=context),\n",
    "        shape=(-1, 1)), mx.nd.array([4], ctx=context)).sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"In 1997 and 1998 Oscar de la Hoya was The Ring magazine's top-rated fighter in the world.\",\n",
       " '\"De La Hoya was named Fighter of the Year by The Ring magazine in 1995 ',\n",
       " '1']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_raw[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gluonnlp.data.dataset.TSVDataset at 0x7f1e6f29b668>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_discard_samples = 1\n",
    "# split fields by tabs\n",
    "field_separator = nlp.data.Splitter(',')\n",
    "# fields to select from the file\n",
    "field_indices = [1, 2]\n",
    "data_test_raw = nlp.data.TSVDataset(filename=\"sample.tsv\",\n",
    "                                     field_separator=field_separator,\n",
    "                                     num_discard_samples=num_discard_samples,\n",
    "                                     field_indices=field_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# use the vocabulary from pre-trained model for tokenization\n",
    "bert_tokenizer = nlp.data.BERTTokenizer(vocabulary, lower=True)\n",
    "# maximum sequence length\n",
    "max_len = 128\n",
    "# the labels for the two classes\n",
    "#all_labels = [\"0\", \"1\"]\n",
    "# whether to transform the data as sentence pairs.\n",
    "# for single sentence classification, set pair=False\n",
    "pair = True\n",
    "transform = dataset.BERTDatasetTransform(bert_tokenizer, max_len,\n",
    "                                         class_labels=None,\n",
    "                                         pad=True,\n",
    "                                         pair=pair)\n",
    "data_test = data_train_raw.transform(transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mxnet.gluon.data.dataset._LazyTransformDataset at 0x7f1e6db8fe48>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "forward() missing 1 required positional argument: 'token_types'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-3688601c653b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/data/anaconda/envs/py35/lib/python3.5/site-packages/mxnet-1.3.0-py3.5.egg/mxnet/gluon/block.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: forward() missing 1 required positional argument: 'token_types'"
     ]
    }
   ],
   "source": [
    "model(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: line 0: export: `=': not a valid identifier\r\n",
      "/bin/sh: line 0: export: `./uncased_L-12_H-768_A-12/': not a valid identifier\r\n"
     ]
    }
   ],
   "source": [
    "!export BERT_BASE_DIR = \"./uncased_L-12_H-768_A-12/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
